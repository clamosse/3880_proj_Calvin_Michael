---
title: "projectCode"
output: word_document
date: "2024-04-16"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tree)
library(randomForest)
library(glmnet)
library(dplyr)
library(gbm)
library(ggplot2)
library(caret)
```



import and split data
```{r}
original_data <- read.csv("data/hermit_lake_weather_and_snow.csv",header=T)
original_data <- select(original_data, -SNWD_change_positive)
# Create a new column large_negative 
original_data <- mutate(original_data, large_negative = ifelse(SNWD_change < -50, 1, 0))
# how many observations saw a large decrease (> 5cm of lost snowpack depth)
sum(select(original_data,large_negative))
#original_data$large_negative <- as.factor(original_data$large_negative)


original_data_SNWD_change <- subset(original_data, select = -large_negative)
original_data_large_negative <- subset(original_data, select = -SNWD_change)

train_size <- floor(0.8 * nrow(original_data))

set.seed(1)
train_indices <- sample(seq_len(nrow(original_data)), size = train_size, replace = FALSE)

train_data <- original_data_SNWD_change[train_indices, ]
test_data <- original_data_SNWD_change[-train_indices, ]

train_data_dichotomized  <- original_data_large_negative[train_indices, ]
test_data_dichotomized  <- original_data_large_negative[-train_indices, ]


```


lm model
```{r}
lm_model <- lm(data = train_data, SNWD_change ~.)
summary(lm_model)

predictions <- predict(lm_model, newdata = test_data)
lm_model_mse <- mean((test_data$SNWD_change - predictions)^2)
lm_model_mse
```

decision tree model
```{r}
tree_model <- tree(data = train_data, SNWD_change ~.)

plot(tree_model)
text(tree_model,cex=.5)

predictions <- predict(tree_model, newdata = test_data)
tree_model_mse <- mean((test_data$SNWD_change - predictions)^2)
tree_model_mse
```

pruning the tree
```{r}
cv_tree <- cv.tree(tree_model)
plot(cv_tree$size, cv_tree$dev, type = "b", xlab = "Tree Size", ylab = "CV Deviance")
optimal_tree_size <- which.min(cv_tree$dev)

tree_prunded <- prune.tree(tree_model, best = optimal_tree_size)
plot(tree_prunded)
text(tree_prunded,cex=.5)

pruned_predictions <- predict(tree_prunded, newdata = test_data)

pruned_mse <- mean((test_data$SNWD_change - pruned_predictions)^2)
pruned_mse
```

bagged model
```{r}
bagged_model <- randomForest(data = train_data, SNWD_change ~., mtry = 27, ntree = 1000, importance = T)
bagged_predictions <- predict(bagged_model, newdata = test_data)
bagged_mse <- mean((test_data$SNWD_change - bagged_predictions)^2)
bagged_mse

importance(bagged_model)
varImpPlot(bagged_model)
```

Boosting
```{r}
boosted_model <- gbm(SNWD_change ~ ., data = train_data, distribution = "gaussian", n.trees = 1000, interaction.depth = 4, shrinkage = 0.01)
summary(boosted_model)

boosted_predictions <- predict(boosted_model, newdata = test_data, n.trees = 1000)

# Calculate MSE
boosted_mse <- mean((test_data$SNWD_change - boosted_predictions)^2)
boosted_mse

```

random forest
```{r}
mse_values <- NULL

for (i in 1:27) {
  rf_model <- randomForest(SNWD_change ~ ., data = train_data, mtry = i, ntree = 500)
  rf_predictions <- predict(rf_model, newdata = test_data)
  mse_values[i] <- mean((test_data$SNWD_change - rf_predictions)^2)
}

mse_values

position <- seq_along(mse_values)
plot(position, mse_values, type = "o", 
     xlab = "Position in the List", ylab = "MSE Values", 
     main = "Plot of MSE Values vs. mtry")


rf_model <- randomForest(SNWD_change ~ ., data = train_data, mtry = 7, ntree = 1000, importance = T)
rf_predictions <- predict(rf_model, newdata = test_data)

rf_mse <- mean((test_data$SNWD_change - rf_predictions)^2)
rf_mse

importance(rf_model)
varImpPlot(rf_model)
```

ridge Regression
```{r}
subset_data <- test_data[, !(names(test_data) == "SNWD_change")]
scaled_data <- scale(subset_data)
test_matrix <- as.matrix(scaled_data)

subset_data <- train_data[, !(names(train_data) == "SNWD_change")]
scaled_data <- scale(subset_data)
train_matrix <- as.matrix(scaled_data)


feature_names <- colnames(subset_data)
feature_names <- c('intercept', feature_names)

#using cv to find best value of lambda
cv.ridge <- cv.glmnet(train_matrix,train_data$SNWD_change, alpha = 0)  # alpha = 1 for Ridge
plot(cv.ridge)
best_lambda <- cv.ridge$lambda.min

#best lasso model
best_ridge <- glmnet(train_matrix,train_data$SNWD_change, alpha = 0, lambda = best_lambda)


#best lasso model coefficients
ridge.coef <- coef(best_ridge)
ridge.coef <- data.frame(ridge.coef@Dimnames[[1]][ridge.coef@i+1],ridge.coef@x)
names(ridge.coef) <- c('var','val')
ridge.coef <- ridge.coef %>% arrange(-abs(val)) %>% print(.,n=25)

  #finding mse
ridge_predictions <- predict(best_ridge, newx = test_matrix)
ridge_mse <- mean((test_data$SNWD_change - ridge_predictions)^2)       
ridge_mse

#finding r2
sst <- sum((test_data$SNWD_change - mean(test_data$SNWD_change))^2)
sse <- sum((ridge_predictions - test_data$SNWD_change)^2)
ridge_r2 <- 1 - sse/sst
ridge_r2
```

Lasso Regression
```{r}
#using cv to find best value of lambda
cv.lasso <- cv.glmnet(train_matrix,train_data$SNWD_change, alpha = 1)  # alpha = 1 for Lasso
plot(cv.lasso)
best_lambda <- cv.lasso$lambda.min

#best lasso model
best_lasso <- glmnet(train_matrix,train_data$SNWD_change, alpha = 1, lambda = best_lambda)

#best lasso model coefficients
lasso.coef <- coef(best_lasso)
lasso.coef <- data.frame(lasso.coef@Dimnames[[1]][lasso.coef@i+1],lasso.coef@x)
names(lasso.coef) <- c('var','val')
lasso.coef <- lasso.coef %>% arrange(-abs(val)) %>% print(.,n=25)

#finding mse
lasso_predictions <- predict(best_lasso, newx = test_matrix)
lasso_mse <- mean((test_data$SNWD_change - lasso_predictions)^2)       
lasso_mse

#finding r2
sst <- sum((test_data$SNWD_change - mean(test_data$SNWD_change))^2)
sse <- sum((lasso_predictions - test_data$SNWD_change)^2)
lasso_r2 <- 1 - sse/sst
lasso_r2

```



=====================
classification models
=====================

log reg model
```{r}
full_logReg_model <- glm(large_negative ~.,data = train_data_dichotomized, family = 'binomial')
summary(full_logReg_model)

predictions <- predict(full_logReg_model, type = "response", newdata = test_data_dichotomized)

threshold <- 0.5
predicted_class <- ifelse(predictions > threshold, 1, 0)
full_log_reg_confusion_matrix <- table(predicted_class, test_data_dichotomized$large_negative)

correct_pred <- sum(diag(full_log_reg_confusion_matrix))
total_pred <- sum(full_log_reg_confusion_matrix)

full_log_reg_accuracy <- correct_pred / total_pred


full_log_reg_confusion_matrix
full_log_reg_accuracy



pruned_logReg_model <- glm(large_negative ~ SNOW + TMAX + windgust,data = train_data_dichotomized, family = 'binomial')
summary(pruned_logReg_model)

predictions <- predict(pruned_logReg_model, type = "response", newdata = test_data_dichotomized)

threshold <- 0.5
predicted_class <- ifelse(predictions > threshold, 1, 0)
log_reg_confusion_matrix <- table(predicted_class, test_data_dichotomized$large_negative)

correct_pred <- sum(diag(log_reg_confusion_matrix))
total_pred <- sum(log_reg_confusion_matrix)

log_reg_accuracy <- correct_pred / total_pred


log_reg_confusion_matrix
log_reg_accuracy

```

```{r}
rf_classification <- randomForest(large_negative ~ ., data = train_data_dichotomized, ntree = 1000)

importance(rf_classification)
varImpPlot(rf_classification)

predictions <- predict(rf_classification, newdata = test_data_dichotomized, type = 'response')

threshold <- 0.5
predicted_class <- ifelse(predictions > threshold, 1, 0)
rf_confusion_matrix <- table(predicted_class, test_data_dichotomized$large_negative)

correct_pred <- sum(diag(rf_confusion_matrix))
total_pred <- sum(rf_confusion_matrix)

rf_accuracy <- correct_pred / total_pred

rf_confusion_matrix
rf_accuracy


```

```{r}
boosted_model <- gbm(large_negative ~ ., data = train_data_dichotomized, n.trees = 1000, interaction.depth = 4, shrinkage = 0.01)


predictions <- predict(boosted_model, newdata = test_data_dichotomized, type = "response")

threshold <- 0.5
predicted_class <- ifelse(predictions > threshold, 1, 0)
boost_confusion_matrix <- table(predicted_class, test_data_dichotomized$large_negative)

correct_pred <- sum(diag(boost_confusion_matrix))
total_pred <- sum(boost_confusion_matrix)

boost_accuracy <- correct_pred / total_pred

boost_confusion_matrix
boost_accuracy


# Convert confusion matrix to data frame
confusion_df <- as.data.frame.table(boost_confusion_matrix)

# Rename columns for clarity
colnames(confusion_df) <- c("Predicted", "Actual", "Count")

# Plot heatmap
ggplot(data = confusion_df, aes(x = Actual, y = Predicted, fill = Count)) +
  geom_tile(colour = "white") +
  geom_text(aes(label = Count), vjust = 1) +
  scale_fill_gradient(low = "lightblue", high = "darkblue") +
  labs(title = "Confusion Matrix",
       x = "Actual",
       y = "Predicted") +
  theme_minimal()
```



=======
MSE for all the models
```{r}

mse_values <- c(lm_model_mse, tree_model_mse, pruned_mse, bagged_mse, rf_mse, ridge_mse, lasso_mse, boosted_mse)

model_names <- c("Linear Regression", "Decision Tree", "Pruned Decision Tree", "Random Forest", "Random Forest (mtry=7)", "Ridge Regression", "Lasso Regression", "Boosting")

plot_data <- data.frame(Model = model_names, MSE = mse_values)

options(repr.plot.width=10, repr.plot.height=6)

ggplot(plot_data, aes(x = Model, y = MSE)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  labs(title = "Mean Squared Error (MSE) of Different Models",
       x = "Model",
       y = "MSE") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  geom_text(aes(label = round(MSE, 2)), vjust = -0.5) +
  theme(legend.position = "none")

```
